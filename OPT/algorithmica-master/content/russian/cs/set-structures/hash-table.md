---
title: Хеш-таблица
authors:
- Александр Гришутин
editors:
- Сергей Слотин
draft: true
---

Аналогично с [хеш-таблицей с помощью
цепочек](Хеш-таблицы_\(цепочки\) "wikilink"),
хеш-таблица с открытым ключом пытается сохранять все ключи, которые в
неё добавляются, в некоторую структуру данных, однако в отличие от
своего брата-близнеца, делает это немного по-другому и гораздо
оптимальнее по памяти.

## Структура

Заведём вектор длины $M$, где $M \~- $ максимальное значение хеш-функции
$h$. По аналогии с хешированием цепочками, сначала это будет небольшая
константа, а по мере заполнения хеш-таблицы мы будем её увеличивать.
Далее в тексте по хеш-функцией $h$ автор имеет в виду остаток от
хеш-функции по модулю $M$.

## Добавление

При добавлении ключа $k$ в хеш-таблицу, мы сначала считаем его хеш,
берём его по модулю $M$, и затем кладём в ячейку с получившимся
номером $h(k)$. Если она занята (например, до этого добавили другой
ключ с таким же значением хеш-функции), то пытаемся положить в
$h(k)+1$, $h(k)+2$ итд до тех пор, пока не найдём свободную ячейку (или
ячейку, из которой что-то удалили, но об этом чуть позже).

## Проверка на наличие

Пусть мы хотим проверить, лежит ли ключ $k$ в нашей хеш-таблице.
Посчитаем $h(k)$ и посмотрим на ячейку с таким номером. Если она
свободна, значит такого ключа нет в таблице (поймите почему\!). Если же
ячейка занята, но там лежит не тот ключ, который мы ищем, пойдём в
$h(k) + 1$ и так до тех пор, пока мы либо не найдём свободную ячейку,
либо не найдём наш ключ, либо не обойдём всю хеш-таблицу, не найдя ни
первого ни второго. Если мы нашли свободную ячейку, то ключа нет, если
мы нашли ключ, то он есть ( =) ), а если мы обошли всю хеш-таблицу и
ничего не нашли, то ключа тоже нет. Более того, если мы обошли всю
хеш-таблицу и все ячейки заняты, то надо провести перехеширование, о
чём можно прочитать ниже.

## Удаление

Чтобы удалить ключ, его сначала надо найти, для этого см. предыдущий
пункт. Затем, если его просто удалить из ячейки, то дальнейшие
поиски, которые должны были бы пройти мимо этой ячейки, наткнутся
на пустую ячейку и решат, что ключа, который они ищут нет, что может
быть неверно. Поэтому вместо удаления мы будем класть в такие ячейки
специальное значение *DELETED*, которое не встречается среди ключей.

## Перехеширование

Аналогично с хешированием цепочками, будем перехешировать нашу
хеш-таблицу когда load_factor становится больше
$\\frac{3}{4}$. Для этого заведём хеш-таблицу с вдвое большим числом
бакетов и все старые ключи закинем в неё (с новой хеш-функцией), а
старую хеш-таблицу удалим.

## Длинные run'ы

Пусть мы вставили в хеш-таблицу 10 разных ключей с одинаковым значением
хеш-функции. По построению они займут 10 последовательных ячеек таблицы
$i, i+1, \\dots, i + 9$. Если теперь мы захотим вставить 2 ключа со
значением хеш-функции, равным $i - 1$, то первый вставится сразу, а
вот для вставки следующего нам придётся пройти 10 ячеек прежде, чем мы
найдём свободную.

Эта проблема имеет 2 примерно одинаковых по производительности решения:

1.  на $i$-ом шаге мы идём не в ячейку с номером $h(k) + i$, а в $h(k) +
    i^2$
2.  на $i$-ом шаге мы идём в ячейку с номером $h_1(k) + i \\times
    h_2(k)$, где $h_i \~-$ разные хеш-функции.

Благодаря такому решению мы избавляемся от проблемы кластеризации (когда
ключи лежат рядом) и средняя длина run'а (последовательность ячеек,
которую мы проходим в запросе) уменьшается за счёт уменьшения их
пересечений для разных значений хеш-функции.

---

# Задача

Мы реализуем множество строк, к которому поступают запросы вида

  - void **Add(s)** - добавить строку $s$ в множество
  - bool **HasKey(s)** - сказать, лежит ли сейчас в множестве $s$
  - void **Remove(s)** - удалить $s$ из множества, если она там есть

Мы уже можем решить такую задачу с помощью
[хешей](Полиномиальное_хеширование_строк "wikilink"):
заведём set и будем работать не со строками, которые к нам поступают, а
с их хешами. Тогда все операции мы умеем выполнять за $O(log(n))$, где
$n \~-$ максимальное количество строк, которое будет лежать в множестве.

Однако этот метод имеет существенный минус $\~-$ он опирается на
предположение о том, что наше хеширование не допускает коллизии,
а мы уже знаем из [парадокса дней
рождений](Парадокс_дней_рождений#Общая_формулировка "wikilink"),
что это очень сильно предположение. Значит, надо что-то делать с
коллизиями. Более того, структура данных, которую мы сейчас
придумаем, позволит отвечать на запросы не за $O(log(n))$, а за
$O(1)$ в среднем, что, конечно, гораздо лучше.

# Структура

Пусть наша хеш-функция отображает все поступающие объекты в $\[0,
\\dots, M-1\]$. Заведём двумерный динамический массив (vector по-русски)
размера $M$ и в ячейку с номером $i$ (это вектор, будем их называть
бакетами) будем складывать все объекты, хеши которых равны $i$.

Теперь, чтобы положить объект в нашу структуру, нам достаточно посчитать
его хеш и push_back'нуть его в соответствующий бакет. Для проверки на
наличие объекта мы опять же считаем хеш и поочерёдно проверяем все
объекты в соответствующем бакете на равенство интересующему нас.

Чтобы удалить элемент надо сделать следующее: найти его в нужном бакете,
свапнуть с последним и сделать pop_back.

# Оптимизация памяти и перехеширование

Заметим, что сейчас наша структура в тратит как минимум $M$ ячеек
памяти. Если мы хотим хешировать по модулю хотя бы $10^9$, то это
непозволительная роскошь. Давайте изначально положим количество бакетов
равным, скажем, 179, а потом, по мере необходимости, будем увеличивать
их количество.

Однако, наша хешфункция все ещё считает хеш по модулю $M$, а не по
модулю числа бакетов, что же делать? Давайте просто дополнительно
брать остаток от хеша по модулю числа бакетов и класть объект уже туда
($bucket\[h(s) \\mod bucket\\_count\].push\\_back(s)$).

Заметим, что если у нас маленькое число бакетов, то довольно быстро
размер бакета начнёт расти, чего нам не хочется, ведь чем длиннее
цепочка, тем дольше работают операции HasKey и Delete. Значит, если
цепочки становятся слишком длинными, надо увеличить число бакетов,
чтобы цепочки сократились за счёт перераспределения ключей по
бакетам.

Будем увеличивать число бакетов вдвое в тот момент, когда
**load_factor** $=\\frac{\\text{число ключей в таблице}}{\\text{число
бакетов}}$ начнёт превосходить некоторой заданной наперёд константы,
например, $\\frac{3}{4}$.

Заметим, что как только мы увеличили число бакетов, значения хешфункции
по модулю старого числа бакетов для всех ключей, которые лежали в
хеш-таблице, стали неактуальными. Значит, их надо пересчитать. Да,
за $O(\\text{число ключей в таблице})$. Заметим, что поскольку мы
каждый раз увеличиваем число бакетов вдвое, такие *тяжёлые*
операции будут происходить всё реже, хотя и каждый раз
перехешировать придётся больше ключей. Однако, средняя
стоимость одной операции будет $O(1)$.